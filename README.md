# ğŸ§  RAG Knowledge Assistant

Este projeto implementa um pipeline de **RAG (Retrieval-Augmented Generation)** para sistemas de perguntas e respostas baseados em documentos privados. O objetivo Ã© demonstrar a aplicaÃ§Ã£o de **LLMs (Large Language Models)**, **Busca SemÃ¢ntica** e **Engenharia de Prompts** para resolver problemas de negÃ³cio, garantindo que a IA responda com base em um contexto especÃ­fico e nÃ£o apenas em seu treinamento prÃ©vio.

## ğŸš€ Tecnologias Utilizadas

O projeto foi construÃ­do utilizando stack moderna de InteligÃªncia Artificial focada em performance e escalabilidade:

* **Python 3.10+**: Linguagem base.
* **LangChain**: Framework para orquestraÃ§Ã£o de fluxos de IA e manipulaÃ§Ã£o de cadeias de pensamento.
* **FAISS (Facebook AI Similarity Search)**: Banco de dados vetorial para busca eficiente de similaridade (Embeddings).
* **OpenAI API**: Utilizada para geraÃ§Ã£o de Embeddings e modelo de Chat (LLM).
* **TikToken**: TokenizaÃ§Ã£o eficiente para controle de janelas de contexto.

## âš™ï¸ Arquitetura da SoluÃ§Ã£o

O fluxo de trabalho do sistema segue as etapas de um RAG clÃ¡ssico:

1.  **IngestÃ£o de Dados**: Carregamento de documentos textuais (txt, pdf, md).
2.  **Chunking**: DivisÃ£o do texto em fragmentos menores (chunks) para otimizar a recuperaÃ§Ã£o.
3.  **Embedding**: ConversÃ£o dos textos em vetores numÃ©ricos de alta dimensÃ£o.
4.  **Vector Store**: Armazenamento dos vetores utilizando FAISS.
5.  **Retrieval (RecuperaÃ§Ã£o)**: Busca semÃ¢ntica dos trechos mais relevantes Ã  pergunta do usuÃ¡rio.
6.  **Generation (GeraÃ§Ã£o)**: Envio do contexto recuperado + pergunta para o LLM gerar a resposta final.

## ğŸ“‚ Estrutura do Projeto

```bash
rag-knowledge-assistant/
â”œâ”€â”€ data/              # DiretÃ³rio para armazenamento de documentos fonte
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py        # CÃ³digo principal do pipeline RAG
â”œâ”€â”€ requirements.txt   # DependÃªncias do projeto
â””â”€â”€ README.md          # DocumentaÃ§Ã£o